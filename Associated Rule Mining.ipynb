{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Associated Rule Mining.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4LpBNxXBLE6hMvYEOECnO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["https://www.analyticsvidhya.com/blog/2021/08/python-tutorial-working-with-csv-file-for-data-science/"],"metadata":{"id":"xz2lMnRFmPRd"}},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NH78x0wdQxPJ","executionInfo":{"status":"ok","timestamp":1649271926404,"user_tz":-60,"elapsed":9356,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}},"outputId":"c6631795-064b-4345-9b35-999832781256"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: memory_profiler in /usr/local/lib/python3.7/dist-packages (0.60.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n","Requirement already satisfied: line_profiler in /usr/local/lib/python3.7/dist-packages (3.5.1)\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# !ln -s \"/content/drive/My Drive/Academic/CSCM35 - Big Data & Data Mining/coursework 2/Dataset.Small\" \"/content/\"\n","# !ln -s \"/content/drive/My Drive/Academic/CSCM35 - Big Data & Data Mining/coursework 2/Dataset.Large\" \"/content/\"\n","!pip install -U memory_profiler\n","!sudo pip install psutil\n","!pip install line_profiler"]},{"cell_type":"code","source":["from itertools import combinations\n","from collections import Counter\n","import numpy as np\n","import csv\n","import pandas as pd\n","\n","from memory_profiler import profile\n","import tracemalloc\n","import os\n","import psutil"],"metadata":{"id":"b5u30WFOTpxp","executionInfo":{"status":"ok","timestamp":1649271172580,"user_tz":-60,"elapsed":264,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def read_from_file(file_name) :\n","  csvfile = open(file = file_name, mode = 'r') # open file\n","  print(type(csvfile))\n","\n","  csvreader = csv.reader(csvfile, skipinitialspace = True) # csv reader object\n","  rows = [] # empty list\n","  for row in csvreader:\n","    rows.append(row)\n","\n","  csvfile.close() #' close file\n","  return rows\n","\n","def write_to_file(file_name, data) :\n","  file = open(file = file_name, mode = 'w') # file object\n","\n","  csvwriter = csv.writer(file) # csv reader object\n","  for row in data:\n","    csvwriter.writerow(row)\n","\n","  file.close() # close file"],"metadata":{"id":"c6KxqY0GTQBh","executionInfo":{"status":"ok","timestamp":1649269960423,"user_tz":-60,"elapsed":235,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["transactions = read_from_file('Dataset.Small/GroceryStore.csv') # read transactions or database\n","write_to_file('Transactions.csv', transactions) # write transactions or database into another file"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VesjogsS1upZ","executionInfo":{"status":"ok","timestamp":1649269964977,"user_tz":-60,"elapsed":1249,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}},"outputId":"20dc26f0-639c-4770-ecde-431fd2eaa810"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<class '_io.TextIOWrapper'>\n"]}]},{"cell_type":"markdown","source":["**Brute-Force Approach(Frequent itemset mining)**\n","\n","$\n","Number\\ of\\ unique\\ items\\ =\\ d\\\\\n","Number\\ of\\ transactions\\ =\\ N\\\\\n","Average\\ width\\ of\\ a\\ transaction=\\ w\\\\ \\\\\n","Number\\ of\\ all\\ possible\\ combinations\\ =\\\n","\\displaystyle\\sum_{r=1} ^{d} c_{r}\\ =\\ 2^d - 1\\\\\n","Complexity\\ =\\ O(Nw2^{d})\n","$"],"metadata":{"id":"hiiyEGq5r1Xm"}},{"cell_type":"code","source":["def search_database(database, itemset) :\n","  \"\"\"\n","    Search occurance of given itemset in the transaction database\n","    Inputs\n","      database : Transactions : List of lists \n","      itemset : Itemset that should be searched : List\n","    Outputs\n","      occurance : Number of occurance : integer\n","  \"\"\"\n","  frequency = np.count_nonzero([all(item in transaction for item in itemset) for transaction in database])\n","  return frequency\n","\n","def calc_candidate_sup_cnt(database, c_k, k) : \n","  \"\"\"\n","  Calculate support count for all candidate k-itemsets and generate dataframe\n","  Inputs\n","    database : Transactions : List of lists\n","    c_k : Candidate k-itemsets : List of tuples\n","  Output : \n","    c_k_df : Candidate k-itemsets dataframe with support counts\n","  \"\"\"\n","  itemset_df = pd.DataFrame(columns=['item_cnt','itemset','support_cnt'])\n","  for itemset in c_k: # itemset : tuple of items\n","      support_count = search_database(database, itemset)\n","      data_entry = {\n","        \"item_cnt\": k,\n","        \"itemset\": itemset,\n","        \"support_cnt\": support_count\n","      }\n","      itemset_df = itemset_df.append(data_entry, ignore_index = True)\n","  return itemset_df\n","\n","def select_freq_itemsets(c_k, min_sup_cnt) :\n","  \"\"\"\n","  Select frequent k-itemsets from candidate k-itemsets(Candidate elimination)\n","  Inputs\n","    c_k : Candidate k-itemsets : DataFrame(itemset,support_cnt)\n","    min_sup_cnt : minimum support count(hyper parameter) : integer\n","  Outputs\n","    f_k : Frequent k-itemsets : DataFrame(itemset,support_cnt)\n","  \"\"\"\n","  f_k = c_k[c_k['support_cnt'] >= min_sup_cnt] \n","  return f_k\n","\n","def brute_force_approach(database, unique_items, min_sup_cnt, itemset_groups):\n","  \"\"\" \n","  Brute Force Method \n","  Inputs\n","    database : Transaction database : List of lists\n","    unique_items : Unique items in the database : List of items\n","    min_sup_cnt : Minimum support count : intereger\n","    itemset_groups : Required item groups(k values)\n","  Outputs\n","    all_freq_itemsets = Frequent itemsets for given groups = DataFrame\n","  \"\"\"\n","  all_candidate_df = pd.DataFrame(columns=['item_cnt','itemset','support_cnt'])\n","  for k in itemset_groups: # loop number of itemset groups\n","    c_k = combinations(unique_items, k) # create combinations for each itemset group\n","    c_k_df = calc_candidate_sup_cnt(database, c_k, k)\n","    all_candidate_df = all_candidate_df.append(c_k_df, ignore_index = True)\n","\n","  all_freq_itemsets = select_freq_itemsets(all_candidate_df, min_sup_cnt)\n","  return all_freq_itemsets"],"metadata":{"id":"nxQWILyHvSVr","executionInfo":{"status":"ok","timestamp":1649269967950,"user_tz":-60,"elapsed":245,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\"\"\"Small dataset\"\"\"\n","transactions = read_from_file('Dataset.Small/GroceryStore.csv') \n","database = [] # transactions or database\n","for transaction in transactions:\n","  tr_str = ''.join(transaction)\n","  database.append(tr_str.split(','))\n","unique_items = read_from_file('Dataset.Small/Items.txt')[0] # unique items\n","\n","\"\"\" Large dataset \"\"\"\n","# transactions = read_from_file('Dataset.Large/OnlineRetail.csv') \n","# database = [] # transactions or database\n","# for transaction in transactions:\n","#   tr_str = ''.join(transaction)\n","#   database.append(tr_str.split(','))\n","# unique_items = read_from_file('Dataset.Small/Items.txt')[0] # unique items\n","# print(database)\n","\n","min_sup_cnt = 2\n","itemset_groups = [1, 2, 3, 4, 5]\n","freq_itemsets = brute_force_approach(database, unique_items, min_sup_cnt, itemset_groups)\n","print(freq_itemsets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvcLQWK_7lej","executionInfo":{"status":"ok","timestamp":1649269975363,"user_tz":-60,"elapsed":3229,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}},"outputId":"5a0f9e96-55a7-40f4-fe14-72d8678f8614"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["<class '_io.TextIOWrapper'>\n","<class '_io.TextIOWrapper'>\n","(33, 3)\n"]}]},{"cell_type":"markdown","source":["**Apriori Algorithm(Frequent itemset mining)**\n","\n","* Superset is frequent >>> Subset is frequent (Bottom Up)\n","\n","* Sebset is infrequent >>> Superset is infrequent (Top down)\n","\n","* This algorithm has **anti-monotone** propety >>> support of itemset can not exceed support of its subset\n","\n","\n","**Main Steps**\n","\n","* Candidate Generation ($F_{k-1} >> C_{k}$)\n","\n","* Candidate Pruning\n","\n","* Support Counting\n","\n","* Candidate Elimination ($C_{k} >> F_{k}$)\n","\n","**Candidate Pruning ($F_{k-1}Ã—F_{k-1}$)**\n","\n","$Itemset\\ is\\ not\\ frequent\\ if\\ one\\ of\\ its\\ sub\\ itemset\\ is\\ not\\ frequent$\n","\n","* Number of **(k-1)-size subsets** for a **k-itemset** = $C^{K}_{K-1}$ = $K$\n","* Number of **already verified (k-1)-size subsets** at the candidate generation = $2$\n","* Number of subsets for frequency verification stage per each **k-itemset** = $K-2$\n","* Total number of subsets for frequency verification for **all k-itemsets** = $L_{k}\\times(K-2)$"],"metadata":{"id":"lUYANEetVox9"}},{"cell_type":"code","source":["@profile\n","def generate_candidates(f_prv_df, k):\n","  \"\"\"\n","  Generate candidate set for k-itemsets\n","  Input : \n","    f_prv : F(K-1) : DataFrame \n","  Output : \n","    c_k : List of candidate k-itemsets : List of lists\n","  \"\"\"\n","  tracemalloc.start()\n","  c_k = [] # candidate k-itemset\n","  f_prv = f_prv_df['itemset']\n","  f_prv_pairs = combinations(f_prv, 2) # select pair of frequent (k-1)-itemsets\n","  for f_prv_pair in f_prv_pairs:\n","    if(len(f_prv_pair[0]) == 1) : ### K=2 ###\n","      two_itemset = [*f_prv_pair[0],*f_prv_pair[1]]\n","      two_itemset.sort()         \n","      c_k.append(two_itemset)\n","    elif(f_prv_pair[0][0:k-2] == f_prv_pair[1][0:k-2]) :### K>=2 and first (k-2) items are same in both itemsets ###\n","      generated_itemset = f_prv_pair[0][0:k-2]\n","      delta_items = [f_prv_pair[0][k-2],f_prv_pair[1][k-2]]\n","      delta_items.sort()\n","      generated_itemset = [*generated_itemset,*delta_items]\n","      c_k.append(generated_itemset)\n","  print(tracemalloc.get_traced_memory())\n","  tracemalloc.stop()\n","  return c_k\n","\n","def prune_candidates(c_k, f_prv_df, k) :\n","  \"\"\"\n","  Prune candidate set from k-itemsets\n","  Inputs\n","    c_k : candidate k-itemsets : List of lists\n","    f_prv_df : frequent (k-1)-itemsets : DataFrame\n","  Output\n","    c_k_prune : pruned candidate k-itemsets : List of lists\n","  \"\"\"\n","  f_prv = f_prv_df['itemset']\n","  infrq_itemsets = []\n","  ### search candidate k-itemsets to check frequency of its (k-1)-sized subsets\n","  for itemset in c_k :\n","    subsets = combinations(itemset, k-1)\n","    for subset in subsets:\n","      frequency = search_database(f_prv, subset)\n","      if(frequency==0):\n","        infrq_itemsets.append(itemset)\n","        break\n","  ### remove infrequent itemsets from candidate k-itemsets ###\n","  for itemset in infrq_itemsets :\n","    c_k.remove(itemset)\n"],"metadata":{"id":"Ufd1lKSaVv6K","executionInfo":{"status":"ok","timestamp":1649271195998,"user_tz":-60,"elapsed":216,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["\n","# items = ['Bread','Coke', 'Milk','Beer','Diaper','Eggs']\n","# database = [['Bread','Milk'],['Beer','Bread','Diaper','Eggs'],['Beer','Coke','Diaper','Milk'],['Beer','Bread','Diaper','Milk'],['Bread','Coke','Diaper','Milk']]\n","# min_sup_cnt = 3\n","\n","# c_1 = [[item] for item in items] # candidate 1-itemset\n","# c_1 = calc_candidate_sup_cnt(database, c_1, 1)\n","# f_1 = select_freq_itemsets(c_1, min_sup_cnt)\n","\n","# c_2 = generate_candidates(f_1,2) # generate 2-itemset\n","# c_2 = calc_candidate_sup_cnt(database, c_2, 2)\n","# f_2 = select_freq_itemsets(c_2, min_sup_cnt)\n","\n","# c_3 = generate_candidates(f_2,3) # generate 3-itemset\n","# c_3 = calc_candidate_sup_cnt(database, c_3, 3)\n","# f_3 = select_freq_itemsets(c_3, min_sup_cnt)\n","# print(f_1)\n","# print(f_2)\n","# print(f_3)\n","\n","# c_2 = [['Coke', 'Milk'], ['Beer', 'Bread'], ['Bread', 'Diaper'], ['Beer', 'Milk'], ['Diaper', 'Milk'], ['Beer', 'Diaper']]\n","# f_1 = pd.DataFrame({'itemset':[['Bread'],['Beer'],['Diaper']]})\n","# prune_candidates(c_2, f_1, 2)\n","# print(c_2)\n","\n","f_itemsets_store = {}\n","all_itemsets_df = pd.DataFrame(columns=['item_cnt','itemset','support_cnt'])\n","for k in itemset_groups:\n","  if(k>1) :\n","    c_k = generate_candidates(f_itemsets_store[k-1],k) # generate 3-itemset\n","    c_k = calc_candidate_sup_cnt(database, c_k, k)\n","    f_k = select_freq_itemsets(c_k, min_sup_cnt)\n","    all_itemsets_df = all_itemsets_df.append(f_k, ignore_index=True)\n","    f_itemsets_store[k] = f_k\n","  else :\n","    c_1 = [[item] for item in unique_items] # candidate 1-itemset\n","    c_1 = calc_candidate_sup_cnt(database, c_1, 1)\n","    f_1 = select_freq_itemsets(c_1, min_sup_cnt)\n","    all_itemsets_df = all_itemsets_df.append(f_1, ignore_index=True)\n","    f_itemsets_store[1] = f_1\n","\n","print(all_itemsets_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnYQvEz__3Nn","executionInfo":{"status":"ok","timestamp":1649271200323,"user_tz":-60,"elapsed":507,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}},"outputId":"681e6007-6b1b-473c-d7f4-935a566dc7f2"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["ERROR: Could not find file <ipython-input-29-5389b1594985>\n","NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n","(2944, 2944)\n","ERROR: Could not find file <ipython-input-29-5389b1594985>\n","NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n","(2584, 2600)\n","ERROR: Could not find file <ipython-input-29-5389b1594985>\n","NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n","(1496, 2185)\n","ERROR: Could not find file <ipython-input-29-5389b1594985>\n","NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n","(1296, 2281)\n","   item_cnt                        itemset support_cnt\n","0         1                          [JAM]           2\n","1         1                        [MAGGI]           5\n","2         1                       [COFFEE]           8\n","3         1                          [TEA]           7\n","4         1                    [BOURNVITA]           4\n","5         1                   [CORNFLAKES]           6\n","6         1                        [BREAD]          13\n","7         1                      [BISCUIT]           7\n","8         1                         [MILK]           5\n","9         2                   [JAM, MAGGI]           2\n","10        2                   [BREAD, JAM]           2\n","11        2                   [MAGGI, TEA]           4\n","12        2                 [BREAD, MAGGI]           3\n","13        2               [BISCUIT, MAGGI]           2\n","14        2           [COFFEE, CORNFLAKES]           4\n","15        2                [BREAD, COFFEE]           3\n","16        2              [BISCUIT, COFFEE]           2\n","17        2               [BOURNVITA, TEA]           2\n","18        2              [CORNFLAKES, TEA]           2\n","19        2                   [BREAD, TEA]           4\n","20        2                 [BISCUIT, TEA]           2\n","21        2             [BOURNVITA, BREAD]           3\n","22        2          [BISCUIT, CORNFLAKES]           3\n","23        2             [CORNFLAKES, MILK]           2\n","24        2               [BISCUIT, BREAD]           4\n","25        2                  [BREAD, MILK]           4\n","26        2                [BISCUIT, MILK]           2\n","27        3            [BREAD, JAM, MAGGI]           2\n","28        3            [BREAD, MAGGI, TEA]           2\n","29        3          [BISCUIT, MAGGI, TEA]           2\n","30        3  [BISCUIT, COFFEE, CORNFLAKES]           2\n","31        3        [BOURNVITA, BREAD, TEA]           2\n","32        3         [BISCUIT, BREAD, MILK]           2\n"]}]},{"cell_type":"code","source":["@profile\n","\n","def my_func():\n","\n","    a=[]\n","\n","    for i in range(1000):\n","\n","        a.append(i)\n","\n","my_func()"],"metadata":{"id":"51UApytaRIpV","executionInfo":{"status":"ok","timestamp":1649271936858,"user_tz":-60,"elapsed":226,"user":{"displayName":"Deshan Chathusanka","userId":"18273530898968534460"}},"outputId":"7eb8d73e-d6e3-4094-fd64-7a96c3f57cf8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["ERROR: Could not find file <ipython-input-33-e9ddf1dc4c1f>\n","NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n"]}]}]}